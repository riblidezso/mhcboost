{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the performance of Neural networks and Gradient boosted trees  , and a stacked ensemble of both in MHC class I binding prediction\n",
    "\n",
    "\n",
    "---\n",
    "### Background\n",
    "\n",
    "The prediction of MHC peptide binding is an important problem in immunology. Data driven methods give best performance for this task because of complexity of the MHC molecules and the binding process. The most successful machine learning models are Artificial Neural Networks in this area.  I have seen articles describing SVM models, but nobody has tried gradient boosted trees (as far as I know).\n",
    "\n",
    "\n",
    "In the last years a lot of Data Science competitions were won with a framework called Gradient Boosted Trees, especially and implementtion called XGBoost. These models very frequently outperform neural networks in general machine learning tasks. \n",
    "\n",
    "These facts gave me the idea to compare the perfomance of  Neural networks  and Gradient boosted trees and in MHC class I peptide binding prediction.\n",
    "\n",
    "Neural networks and Gradient boosted trees are very different models, therefore ensembling them can give another boost to performance.\n",
    "\n",
    "\n",
    "----\n",
    "### Data\n",
    "\n",
    "#### Source\n",
    "I have downloaded MHC class I peptide binding data which has been used in this benchmark article ( http://www.ncbi.nlm.nih.gov/pubmed/25017736)  from the IEDB website.\n",
    "\n",
    "\n",
    "#### Encoding \n",
    "\n",
    "Input data is very simply coded as the folowing:\n",
    "- zero padded sequences to the longest peptide length\n",
    "    - state of the art models use more sophisticated prediction on different length peptides, but for demonstration purpose I didn't want to recreate those.\n",
    "- amino acids are encoded in a one hot scheme, or Blosum encoding\n",
    "- original peptide lengths are included\n",
    "\n",
    "#### Target \n",
    "\n",
    "I predict IC50 binding data transformed as the following (from netmhc articles):\n",
    "\n",
    "$y = 1 - \\log_{10}(IC50)/ \\log_{10}(50000)$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Models\n",
    "\n",
    "#### Neural network\n",
    "\n",
    "I use a neural network architecture similar to the one used in NetMHC.\n",
    "- 1 hidden layer\n",
    "- 5 units in the hidden layer\n",
    "- tanh activations for hidden layer, sigmoid for the final layer, these are only guesses I have found no description of activation in NetMHC arrticles.\n",
    "\n",
    "I use the Keras library. http://keras.io\n",
    "\n",
    "\n",
    "#### Gradient boosted trees\n",
    "Some resources about the model:\n",
    "- http://xgboost.readthedocs.org/en/latest/model.html\n",
    "- http://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf\n",
    "    \n",
    "I used the XGBoost software library. http://xgboost.readthedocs.org/en/latest/\n",
    "\n",
    "\n",
    "#### Ensembling\n",
    "\n",
    "I simply used the mean of different predictions, as described in several NetMHC articles.\n",
    "\n",
    "---\n",
    "\n",
    "### Methods\n",
    "\n",
    "\n",
    "I have done nested 5-fold cross validation evaluations. All models use early stopping on validation data. Validation data is a random10% subset of the 4 folds of traning data.\n",
    "\n",
    "The folds used were defined in the benchmark article as the group similarity (cv_gs) folds.\n",
    "\n",
    "\n",
    "\n",
    "--- \n",
    "\n",
    "### Conclusions\n",
    "\n",
    "\n",
    "The Gradient Boosted Trees outperforms Neural Networks. The ensemble of these 2 models adds a further improvement.\n",
    "\n",
    "Note that my NN ensemble perform significantly worse than NetMHC. It can be because of the treatment of different peptide lengths, or other differences between the my ensemble and NetMHC. I'm not sure about this.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Future Work\n",
    "\n",
    "#### Adding Gradient Boosted trees to the NetMHC ensemble\n",
    "\n",
    "I think adding Gradient Boosted trees to the NetMHC ensemble could further imporove its peforance as demonstrated in the notebook.\n",
    "\n",
    "\n",
    "#### Further ideas for improvement:\n",
    "\n",
    "- Hypterparameter optimization for xgb\n",
    "- Sophisticated handling of different length peptides, see literature.\n",
    "- Different NN architectures for alleles with different number of training data available.\n",
    "- Get the MHC pseudosequence data and repeat the comparison with netmhcpan.\n",
    "- (More realistic random peptides.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "#### Notes\n",
    "\n",
    "- To run this notebook you need to \n",
    "    - download the dataset\n",
    "    - and have keras,theno,xgboost,sklearn,pandas,numpy installed\n",
    "    - see the docker image for a ready enviroment\n",
    "    \n",
    "    \n",
    "    \n",
    "- This notebook can be run as it is. Just click run all. \n",
    "    - It takes some time but on a stronger computer it should be less than 30 minutes.\n",
    "    \n",
    "- It takes several hours to run this notebook!\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "This notebook was created by Dezso Ribli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import xgboost as xgb\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#go to working dir\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(blosum=False):\n",
    "    \"\"\"Load train/blind test data as in the benchmark.\"\"\"\n",
    "    #load the cross validation data\n",
    "    dataf='input/benchmark_mhci_reliability/binding/bd2009.1/bdata.2009.mhci.public.1.cv_gs.txt'\n",
    "    data=pd.read_csv(dataf,sep='\\t')\n",
    "    \n",
    "    #select only with length 8-12, anyway only those will be evauated\n",
    "    data=data[(data.peptide_length >=8) & (data.peptide_length <12)]\n",
    "     \n",
    "    #encode amino acids\n",
    "    X_seq=encode_seq(data.sequence.values,data.sequence.values,blosum)\n",
    "    \n",
    "    #stack columns\n",
    "    X=np.column_stack([X_seq,data.peptide_length.values])\n",
    "    \n",
    "    #make target variable\n",
    "    y = 1 - np.log10(data.meas)/np.log10(50000)\n",
    "    data['meas_tf']= y\n",
    "    \n",
    "    #make a label target in the dataframe for binding\n",
    "    label=np.ones(len(data.meas))\n",
    "    label[data.meas.values>=500]=0\n",
    "    data['label']=label\n",
    "\n",
    "    #permute arrays\n",
    "    rng=np.random.RandomState(42)\n",
    "    perm=rng.permutation(len(X))\n",
    "    X,y,data=X[perm],y[perm],data.iloc[perm,:].reset_index(drop=True)\n",
    "    \n",
    "    return X,y,data\n",
    "\n",
    "\n",
    "def encode_seq(x_all,x_in,blosum):\n",
    "    \"\"\"Encode string amino acid sequences to numbers.\"\"\"\n",
    "    if blosum:\n",
    "        return encode_seq_blosum(x_all,x_in)\n",
    "    else:\n",
    "        return encode_seq_one_hot(x_all,x_in)\n",
    "\n",
    "def encode_seq_one_hot(x_all,x_in):\n",
    "    \"\"\"Encode string amino acid sequences to numbers with one hot encoding.\"\"\"\n",
    "    #zero pad peptids to equal length\n",
    "    x_temp_all=np.array([list(x.zfill(11)) for x in x_all])\n",
    "    x_temp_in=np.array([list(x.zfill(11)) for x in x_in])\n",
    "    \n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(x_temp_all.flatten())\n",
    "    x_out=np.column_stack([lb.transform(x_temp_in[:,i]) for i in range(11)])\n",
    "\n",
    "    return x_out\n",
    "\n",
    "def encode_seq_blosum(x_all,x_in):\n",
    "    \"\"\"Encode string amino acid sequences to numbers with blosum encoding.\"\"\"\n",
    "    #zero pad peptids to equal length\n",
    "    maxlen=np.max(map(len,x_all))\n",
    "    x_temp_all=np.array([list(x.zfill(11)) for x in x_all])\n",
    "    x_temp_in=np.array([list(x.zfill(11)) for x in x_in])\n",
    "\n",
    "    blosum62 = pd.read_csv('input/BLOSUM62.txt',header=None,skiprows=7,delim_whitespace=True,index_col=0)\n",
    "    blosum_dict=blosum62.transpose().to_dict(orient='list')\n",
    "    blosum_dict['0']=blosum_dict['*']\n",
    "    \n",
    "    #transform\n",
    "    x_out=np.column_stack([[blosum_dict[x_temp_in[i,j]] for i in xrange(len(x_in)) ] for j in range(11)])\n",
    "\n",
    "    return x_out\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"For netmhc results:\"\"\"\n",
    "\n",
    "def load_all_tables(path):\n",
    "    \"\"\"Load all tables in directory and concat them into one big table\"\"\"\n",
    "    return pd.concat([load_allele_table(f,all_from_fname(f)) for f in glob.glob(path)])\n",
    "\n",
    "def load_allele_table(fname,allele):\n",
    "    \"\"\"Load a result table and annotate with allele\"\"\"\n",
    "    #note they are .xls but csv files...\n",
    "    tmp_table=pd.read_csv(fname,sep='\\t')\n",
    "    tmp_table['mhc']=allele.replace('_','-')\n",
    "    tmp_table['peptide_length']=[len(x) for x in tmp_table.sequence]\n",
    "    tmp_table['label']=(tmp_table.meas <= np.log10(500)).astype('int')\n",
    "    tmp_table['pred_tf']=1-tmp_table.pred.values/np.log10(50000)\n",
    "    return tmp_table\n",
    "\n",
    "\n",
    "def all_from_fname(fname):\n",
    "    \"\"\"Get allele from the filename\"\"\"\n",
    "    # a bit convoluted naming\n",
    "    return '_'.join(os.path.basename(fname).split('cv_gs.')[-1].split('.')[0].split('-')[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for adding random peptides to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_all_random_peptides(x_in):\n",
    "    #create random peptides\n",
    "    random_peptides,lengs=[],[]\n",
    "    for i in xrange(8,12):\n",
    "        for j in xrange(25):\n",
    "            random_peptides.append(create_random_peptide(i))\n",
    "            lengs.append(i)\n",
    "\n",
    "    #encode amino acids\n",
    "    if x_in.size==232:\n",
    "        X_seq=encode_seq(random_peptides,random_peptides,blosum=False)\n",
    "    else:\n",
    "        X_seq=encode_seq(random_peptides,random_peptides,blosum=True)\n",
    "    \n",
    "    #stack columns\n",
    "    X=np.column_stack([X_seq,lengs])\n",
    "    \n",
    "    #return a binding too\n",
    "    y= 0.1 *np.random.random(len(random_peptides))\n",
    "        \n",
    "    return X,y\n",
    "\n",
    "def create_random_peptide(leng):\n",
    "    aa=['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P','Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "    return ''.join(np.random.choice(aa) for _ in range(leng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "\n",
    "### Cross validation scheme for both models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_gs(fitter,model_spec,X,y,data,add_random_peptides=True,**kwargs):\n",
    "    \"\"\"Evaluate XGB model with cross validation.\"\"\"\n",
    "    #result\n",
    "    y_pred=np.zeros(len(y))\n",
    "    #loop folds\n",
    "    for i in xrange(5):\n",
    "        #select folds\n",
    "        test_idx=data.cv.values==i\n",
    "        train_idx=~( test_idx)\n",
    "        \n",
    "        if add_random_peptides:\n",
    "            #add random peptides\n",
    "            rx,ry=create_all_random_peptides(X[0])\n",
    "            X_train=np.concatenate([X[train_idx],rx])\n",
    "            y_train=np.concatenate([y[train_idx],ry])\n",
    "\n",
    "            #permute arrays\n",
    "            rng=np.random.RandomState(42)\n",
    "            perm=rng.permutation(len(X_train))\n",
    "            X_train,y_train=X_train[perm],y_train[perm]\n",
    "        else:\n",
    "            X_train,y_train=X[train_idx],y[train_idx]\n",
    "        \n",
    "        #train and predict\n",
    "        y_pred[test_idx]=fitter(model_spec,\n",
    "                                  X_train,y_train,\n",
    "                                  X[test_idx],**kwargs)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def nn_fit(get_model,X_train,y_train,X_test,\n",
    "                      patience=10,nb_epoch=100,**kwargs):\n",
    "    \"\"\"Fit model on train test set with early stopping.\"\"\"\n",
    "    #get model\n",
    "    model=get_model(X_train.shape[1])\n",
    "    \n",
    "    #callbacks\n",
    "    best_model=ModelCheckpoint('best_model',save_best_only=True,verbose=0)\n",
    "    early_stop=EarlyStopping(patience=patience,verbose=0)\n",
    "    \n",
    "    #train it\n",
    "    model.fit(X_train,y_train,nb_epoch = nb_epoch,validation_split=0.1,\n",
    "              callbacks=[best_model,early_stop],verbose=0,**kwargs)\n",
    "    \n",
    "    #load best model and predict\n",
    "    model.load_weights('best_model')\n",
    "    y_pred_test=model.predict(X_test).ravel()\n",
    "    \n",
    "    return y_pred_test\n",
    "\n",
    "def xgb_fit(params,X_train,y_train,X_test,\n",
    "                    num_boost_round=20000,verbose_eval=False,\n",
    "                    early_stopping_rounds=1000,validation_size=0.1):\n",
    "    \"\"\"Fit model on train test set with early stopping.\"\"\"\n",
    "    #set seed to get randomized results\n",
    "    params['seed']=np.random.randint(low=0,high=1000)\n",
    "    \n",
    "    #split validation data for early stopping\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "    \n",
    "    #convert to data format for xgb\n",
    "    dtrain = xgb.DMatrix( X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix( X_valid, label=y_valid)\n",
    "    dtest = xgb.DMatrix( X_test )\n",
    "    \n",
    "    #define printed evaluations\n",
    "    evallist  = [(dtrain,'train'),(dvalid,'eval')]\n",
    "\n",
    "    #lets train\n",
    "    bst = xgb.train(params,dtrain,evals=evallist,\n",
    "                    num_boost_round=num_boost_round,\n",
    "                    early_stopping_rounds=early_stopping_rounds,\n",
    "                    verbose_eval=verbose_eval)\n",
    "    \n",
    "    #make predictions\n",
    "    y_pred_test=bst.predict(dtest)\n",
    "    \n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcions to train ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_ensemble(X,X_blosum,y,data,fitter,model,n_sparse=10,n_blosum=10):\n",
    "    \"\"\"Train an ensemble of models, make prediction using mean.\"\"\"\n",
    "    #train sparse models\n",
    "    cv_preds_sparse=[cv_gs(fitter,model,X,y,data) for i in xrange(n_sparse) ]\n",
    "\n",
    "    #train blosum models\n",
    "    cv_preds_bls=[cv_gs(fitter,model,X_blosum,y,data) for i in xrange(n_blosum)]\n",
    "        \n",
    "    #create final prediction from the mean of predictions\n",
    "    final_preds=np.array(cv_preds_sparse+cv_preds_bls).mean(axis=0)\n",
    "    \n",
    "    return final_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the details of single models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mhc_net(input_dim,n_dense=5):\n",
    "    \"\"\"\n",
    "    Create a Keras model similar to netmhc networks.\n",
    "    \n",
    "    Activations were selected after some trials. I dont know what netmhc uses.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_dense, input_dim=input_dim,activation='tanh'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "#xgboost model params\n",
    "xgb_params = {'max_depth':5,\n",
    "         'eta':0.005,\n",
    "         'min_child_weight':10,\n",
    "         'colsample_bytree':0.7,\n",
    "         'subsample':0.8,\n",
    "         'silent':1,\n",
    "         'objective': \"reg:linear\",\n",
    "         'eval_metric': 'rmse',\n",
    "         'nthread':4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,y,data=load_data()\n",
    "X_bls,y,data=load_data(blosum=True)\n",
    "netmhc_cv_res=load_all_tables('input/benchmark_mhci_reliability/predictions/cv_gs/netmhc/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to select one allele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def select_allele(allele,X,X_bls,y,data,netmhc_cv_res):\n",
    "    \"\"\"Return data from only one allele\"\"\"\n",
    "    #index\n",
    "    all_idx=(data.mhc==allele).values\n",
    "    #X\n",
    "    X_tmp=X[all_idx]\n",
    "    X_tmp_bls=X_bls[all_idx]\n",
    "    #y\n",
    "    y_tmp=y[all_idx]\n",
    "    #additional data\n",
    "    data_tmp=data[all_idx]\n",
    "    #netmhc preds\n",
    "    netmhc_tmp=netmhc_cv_res[all_idx]\n",
    "    return all_idx,X_tmp,X_tmp_bls,y_tmp,data_tmp,netmhc_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict all alleles\n",
    "- This takes long long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H-2-Db H-2-Dd H-2-Kb H-2-Kd H-2-Kk H-2-Ld HLA-A-0101 HLA-A-0201 HLA-A-0202 HLA-A-0203 HLA-A-0206 HLA-A-0211 HLA-A-0212 HLA-A-0216 HLA-A-0219 HLA-A-0250 HLA-A-0301 HLA-A-1101 HLA-A-2301 HLA-A-2402 HLA-A-2403 HLA-A-2501 HLA-A-2601 HLA-A-2602 HLA-A-2603 HLA-A-2902 HLA-A-3001 HLA-A-3002 HLA-A-3101 HLA-A-3201 HLA-A-3301 HLA-A-6801 HLA-A-6802 HLA-A-6901 HLA-A-8001 HLA-B-0702 HLA-B-0801 HLA-B-0802 HLA-B-0803 HLA-B-1501 HLA-B-1502 HLA-B-1503 HLA-B-1509 HLA-B-1517 HLA-B-1801 HLA-B-2703 HLA-B-2705 HLA-B-3501 HLA-B-3801 HLA-B-3901 HLA-B-4001 HLA-B-4002 HLA-B-4402 HLA-B-4403 HLA-B-4501 HLA-B-4601 HLA-B-4801 HLA-B-5101 HLA-B-5301 HLA-B-5401 HLA-B-5701 HLA-B-5801 HLA-B-7301 Mamu-A-01 Mamu-A-02 Mamu-A-11 Mamu-A-2201 Mamu-B-01 Mamu-B-03 Mamu-B-08 Mamu-B-17 Patr-A-0101 Patr-A-0301 Patr-A-0401 Patr-A-0701 Patr-A-0901 Patr-B-0101 Patr-B-1301 Patr-B-2401\n"
     ]
    }
   ],
   "source": [
    "res_data=pd.DataFrame(data,copy=True)\n",
    "for allele in np.unique(data.mhc.values):\n",
    "    #select allele\n",
    "    all_idx,X_tmp,X_tmp_bls,y_tmp,data_tmp,netmhc_tmp=select_allele(allele,X,X_bls,y,data,netmhc_cv_res)\n",
    "\n",
    "    #nn ensemble\n",
    "    nn_pred=mean_ensemble(X_tmp,X_tmp_bls,y_tmp,data_tmp,nn_fit,mhc_net,n_sparse=10,n_blosum=10)\n",
    "    #xgb ensemble\n",
    "    xgb_pred=mean_ensemble(X_tmp,X_tmp_bls,y_tmp,data_tmp,xgb_fit,xgb_params,n_sparse=1,n_blosum=1)\n",
    "    #nn+xgb\n",
    "    nn_xgb_pred=np.array(np.concatenate([[nn_pred],[xgb_pred]])).mean(axis=0)\n",
    "    \n",
    "    #save preds\n",
    "    res_data.loc[all_idx,'nn']=nn_pred\n",
    "    res_data.loc[all_idx,'xgb']=xgb_pred\n",
    "    res_data.loc[all_idx,'nn_xgb']=nn_xgb_pred\n",
    "    \n",
    "    print allele,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_data.to_csv('all_specific_training_results_no_nestcv.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A bit convoluted way to aggregate in pandas dataframes on multiple columns with different column names,\n",
    "but now it will be okay. I will look into this later maybe.\n",
    "\"\"\"\n",
    "\n",
    "def agg_auc_nn(group):\n",
    "    return agg_auc(group,'nn')\n",
    "\n",
    "def agg_auc_xgb(group):\n",
    "    return agg_auc(group,'xgb')\n",
    "\n",
    "def agg_auc_nn_xgb(group):\n",
    "    return agg_auc(group,'nn_xgb')\n",
    "\n",
    "def agg_auc_netmhc(group):\n",
    "    return agg_auc(group,'pred_tf')\n",
    "\n",
    "def agg_auc_netmhc_xgb(group):\n",
    "    return agg_auc(group,'netmhc_xgb')\n",
    "\n",
    "\n",
    "def agg_auc(group,col):\n",
    "    y = group['label_x'].values\n",
    "    pred = group[col].values\n",
    "    \n",
    "    if len(np.unique(y))==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return roc_auc_score(y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge with netmhc res\n",
    "all_res=res_data.merge(netmhc_cv_res,on=['mhc','sequence'])\n",
    "\n",
    "#add a netmhc xgb ensemble\n",
    "all_res['netmhc_xgb']=0.5*(all_res.pred_tf+all_res.xgb)\n",
    "\n",
    "## aggregate\n",
    "grouped=all_res.groupby('mhc',as_index=False)\n",
    "\n",
    "#get auc\n",
    "all_auc_df=grouped.agg(agg_auc_nn)[['mhc']]\n",
    "all_auc_df['counts']=grouped['mhc'].size().values\n",
    "all_auc_df['nn']=grouped.agg(agg_auc_nn)[['cv']]\n",
    "all_auc_df['xgb']=grouped.agg(agg_auc_xgb)[['cv']]\n",
    "all_auc_df['nn_xgb']=grouped.agg(agg_auc_nn_xgb)[['cv']]\n",
    "all_auc_df['netmhc']=grouped.agg(agg_auc_netmhc)[['cv']]\n",
    "all_auc_df['netmhc_xgb']=grouped.agg(agg_auc_netmhc_xgb)[['cv']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaged results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetMHC AUC: 0.904293891309\n",
      "my nn mean AUC: 0.897869533861\n",
      "my xgb mean AUC: 0.907416522918\n",
      "my nn+xgb mean AUC: 0.910406232264\n",
      "NetMHC + xgb mean AUC: 0.914596805599\n"
     ]
    }
   ],
   "source": [
    "print \"NetMHC AUC:\", all_auc_df['netmhc'].mean()\n",
    "print \"my nn mean AUC:\", all_auc_df['nn'].mean()\n",
    "print \"my xgb mean AUC:\", all_auc_df['xgb'].mean()\n",
    "print \"my nn+xgb mean AUC:\", all_auc_df['nn_xgb'].mean()\n",
    "print \"NetMHC + xgb mean AUC:\", all_auc_df['netmhc_xgb'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble outperformed netmhc when the number of measurements were small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAF+CAYAAACFwM5IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3XmYHFXZ9/FvZyBhICQzmA1MwmLomx1JWF2DgDygD4sS\nEXhe2RQhgAhu4IaCCqIgKAZBREBFJYgBBUTAAAphC4sgcIewBkIWYCaBGAhJ+v3jVJNOZ3qmuqd6\nqe7f57rmSrrqVPV9pqa77z51lkwul0NERESk1QyodwAiIiIi9aAkSERERFqSkiARERFpSUqCRERE\npCUpCRIREZGWpCRIREREWpKSIBEREWlJSoJERESkJSkJEhERkZakJEhERERa0lr1DqBSZnY88GVg\nFPAIcKK731+i7IHAccB7gUHAf4DvuPvfi8pNAs4ANgFmAae6+03VqoOIiIjUTypbgszsYOBc4HRg\nB0ISdLOZDStxyIeAvwP7AOOB6cBfzGz7gnO+D7gK+CUhWboOmGZmW1WrHiIiIlI/mTQuoGpm9wD3\nuvtJ0eMMMAf4qbufE/McjwF/cPfvRY//AKzr7vsVlJkBPOTuk5Oug4iIiNRX6lqCzGxtYAJwW36b\nu+eAW4HdYp4jA6wPvFawebfoHIVujntOERERSZfUJUHAMKANmF+0fT6hf1AcXwHWA64u2Daqn+cU\nERGRFEltx+hKmdmhwLeA/dz9laTPn8vlcplMJunTioiItIKafoCmMQl6BVgBjCzaPhKY19uBZvZp\n4BLgIHefXrR7XiXnLJbJZFi8eCkrVqws57CG1NY2gCFD2lWfBtRMdQHVp5E1U11A9Wlk+brUUuqS\nIHd/28xmAnsA18M7fXz2AH5a6jgzOwS4FDjY3f/WQ5EZPZxjr2h7WVasWMny5en+Yyyk+jSuZqoL\nqD6NrJnqAqqPBKlLgiLnAZdHydB9wMnAusDlAGZ2FrCRux8ePT402vcF4H4zy7f4LHX3xdH/LwBu\nN7NTgBuAQwgdsD9XiwqJiIhIbaWxYzTufjVhosQzgIeA7YC93X1hVGQUMKbgkM8ROlP/HJhb8HN+\nwTlnAIcCxwAPA58A9nf3x6taGREREamLVM4T1OByXV1LmqJZcq21BtDZuR6qT+NpprqA6tPImqku\noPo0sqguNe0YncqWIBEREZH+UhIkIiIiLUlJkIiIiLQkJUEiIiLSktI6RL6p5XI5Zs3ppvuNZXQM\nHkh2TAeahVpERCRZSoIazExfyNTps1nQvfSdbSM62pm0+zgm2PA6RiYiItJcdDusgcz0hUyZ9uhq\nCRDAgu6lTJn2KDPfmQZJRERE+ktJUIPI5XJMnT6bUtM25XIw9fbZaF4nERGRZCgJahCz5nSv0QJU\nbEHXUp56cVGNIhIREWluSoIaRPcby2KWe6vKkYiIiLQGJUENomPwwJjlBlU5EhERkdagJKhBZMd0\nMKKjvdcyIzrb2Xz00BpFJCIi0tyUBDWITCbDpN3HUWo6oEwGJk0cp/mCREREEqIkqIFMsOFMPmBb\nRnSu3iI0orOdyQdsq3mCREREEqTJEhvMBBvO+OwwZs3pZtGSZXQMHsTmo4eqBUhERCRhSoIaUCaT\nwcZ21jsMERGRpqbbYSIiItKSlASJiIhIS1ISJCIiIi1JSZCIiIi0JCVBIiIi0pKUBImIiEhLUhIk\nIiIiLUlJkIiIiLQkJUEiIiLSkpQEiYiISEuKtWyGmQ0CjgHud/d7SpTZFdgJuNjdlyUXooiIiEjy\n4q4dNhn4GrBFL2WeAK6N/v+z/gQlIiIiUm1xb4d9GviZu3eXKuDui4ALgcOSCExERESkmuImQVsD\nM2KUuycqKyIiItLQ4iZBmSqcU0RERKRu4iYszwDvj1Hu/VFZERERkYYWNwm6BjjZzLYsVSDa90Xg\n6iQCExEREammuKPDfgwcBNxnZhcBNwMvADlgLLA3cBzwHHBe8mGKiIiIJCtWEuTuS8xsInAR8KXo\np9g1wGR3X5JceCIiIiLVEbclCHd/FfiUmY0FPgi8O9r1EnCnu8+pQnwiIiIiVRE7Ccpz9xeA31Uh\nFhEREZGaibtsxod62f02sMDdn04mJBEREZHqi9sSdDuhE3Sp+YJyZvYy8C13/3USgYmIiIhUU9wk\naIde9rUBGwEHApea2RJ31zB5ERERaWhxR4c90keRB4G/mtlKwsgxJUEiIiLS0JJe4mIaWjtMRERE\nUkDrfImIiEhLSjoJ2h94LOFzioiIiCQu7hD58b3sbgNGERKgI4FDEohLREREpKrijg57gDBEvpQM\n8DLweY0MExERkTSImwTt3su+5cBC4Cl37y1REhEREWkYcYfI3xH3hGa2qbs/W3lIIiIiItVX9tph\nPTGzYcDBwKHAroR+QiIiIiINq+IkyMzWJcwSfSiwZ3Suh4GTkwlNREREpHrKSoLMrA34H0Lisx+w\nLjAvOs8h6hQtIiIiaRF3iPz7CYnPJGAY8CrwW+AqwrxArxKSoZoxs+OBLxOG5z8CnOju95coOwo4\nF9gRGAdc4O6nFJU5HPg1qy8U+6a7r1udGoiIiEg9xZ0s8Z/AscC/gY8DG7r7ce7+T2BltYIrxcwO\nJiQ1pxMWd30EuDnqm9STQcAC4EzCLbtSFhGSqvzPxknFLCIiIo0l7u2wR4FtgQ8DK4BhZvZnd3+9\napH17mTgYne/EsDMjgU+BhwFnFNc2N2fj47BzI7u5bw5d1+YfLgiIiLSaGK1BLn79sA2wI+AzYHL\ngXlmdjVhpuiazQ9kZmsDE4DbCuLLAbcCu/Xz9IPN7Dkze8HMppnZVv08n4iIiDSo2B2j3f1x4OvA\n1wv6CB0U/eSAk8wMd7+zKpGuMowwBH9+0fb5gPXjvE5oSfo3MBT4CnC3mW3l7nPLOVFbW3OsS5uv\nh+rTeJqpLqD6NLJmqguoPo2sHnWoaIi8u98F3GVmXwD2JqwXtj9wgJk97+6bJRhjTbj7PcA9+cdm\nNgN4Avg8oe9RbEOGtCcbXJ2pPo2rmeoCqk8ja6a6gOojQb8mS3T3FcCNwI1m1g4cQPUXUH2F0C9p\nZNH2kSQ4Qs3dl5vZQ4TRZGVZvHgpK1bUvL944traBjBkSLvq04CaqS6g+jSyZqoLqD6NLF+XWkpk\nxmgAd18K/D76qRp3f9vMZgJ7ANcDmFkmevzTpJ7HzAYQOoPfUO6xK1asZPnydP8xFlJ9Glcz1QVU\nn0bWTHUB1UeCxJKgGjsPuDxKhu4jjPxal9BhGzM7C9jI3Q/PH2Bm2xPm/xkMDI8eL3P3J6L93yLc\nDpsNdABfBcYCl9aoTiIiIlJDqUyC3P3qaE6gMwi3wR4G9i4Y3j4KGFN02EOsGsU2ntCx+3kg33+p\nE7gkOrYLmAns5u5PVqseIiIiUj+ZXK5mo9tbRa6ra0lTNEuutdYAOjvXQ/VpPM1UF1B9Glkz1QVU\nn0YW1SXTd8nkpH9MnYiIiEgFyk6CzGx9M9uwxL4NzWxw/8MSERERqa5K+gRdCrwOfLaHfd8ldDw+\ntD9BiYiIiFRbJbfDPkTpYeM3EtYXExEREWlolSRBnYSWoJ4sAd5VeTgiIiIitVFJEvQMsGeJfXsA\nz1UcjYiIiEiNVNon6Gwzew24zN1fiebsOZIwaeHXkwxQREREpBoqSYJ+ArwHOAs4y8yWF5znF+5+\nblLBiYiIiFRL2UmQu+eA483sfMLtrw2AV4F/uPtTCccnIiIiUhUVL5sRJTxKekRERCSVKkqCzKwN\n2AUYDaxTvN/dr+xnXCIiIiJVVXYSZGbjgWsJC5T2tMZHDlASJCIiIg2tkpagi4BFwOHA48CyRCMS\nERERqYFKkqCtgUnufkfSwYiIiIjUSiWTJc4ChiQdiIiIiEgtVZIEnQycZmZbJB2MiIiISK3Euh1m\nZo8SOjznbQg8ZmZzge6i4jl33z6h+ERERESqIm6foJmsngSJiIiIpFqsJMjdj6hyHCIiIiI1VUmf\nIBEREZHUq3TG6F2BSYQJE4tnjM65+/79DUxERESkmiqZMfokwkryC4Cn0WSJIiIikkKVtAR9GbgQ\n+KK7r0w4HhEREZGaqKRP0HrAdUqAREREJM0qSYL+COyTdCAiIiIitVTJ7bAvApea2VXAraw5WSLu\nfm1/AxMRERGppkqSoC2A9wObAJ/uYX8OaOtHTCIiIiJVV0kSdBnwBvC/hMVUNTpMREREUqeSJGhL\n4BPu/rekgxERERGplUo6Rj8MjEw6EBEREZFaqiQJmgycbGYfNbOKZpwWERERqbdKkph/AmsDNwEr\nzWxp0f6cuw/td2QiIiIiVVRJEnQuYQSYiIiISGqVnQS5+3eqEIeIiIhITZXdJ8jM/mFmW5TYlzWz\nf/Q/LBEREZHqqqRj9ERgSIl9Q4APVRyNiIiISI1UkgRB6T5B7wMWVHhOERERkZqJ1SfIzE4DTose\n5oDpZla8ivyg6HxTkgtPREREpDridoy+mzAqLAN8G/g98GJRmWXAE8BfEotOREREpEpiJUHufgdw\nB4CZ5YBfuvvcagYmIiIiUk2VDJH/bv7/ZjYGGAM84u5LkgxMREREpJoqWvbCzI4BTgc2JPQR2gl4\n0Mz+DNzu7hckF6LI6nK5HLPmdNP9xjI6Bg8kO6aDTCZT77BERCRlyk6CzOyLwA+B84DbgL8X7L4d\nmAQoCZKqmOkLmTp9Ngu6V63WMqKjnUm7j2OCDa9jZCIikjaVDJE/ETjT3U8Dphftc8D6HZVID2b6\nQqZMe3S1BAhgQfdSpkx7lJm+sE6RiYhIGlWSBL2bMFqsJ28DgysPR6RnuVyOqdNnkysxQ1UuB1Nv\nn02uVAEREZEilSRBzwM7l9i3CzCr8nBEejZrTvcaLUDFFnQt5akXF9UoIhERSbtKkqBfAt80s6NZ\ntXzG2mb2MeArwMVJBSeS1/3Gspjl3qpyJCIi0izKToLc/cfAZcAlQL4Txl3AdcBv3F0zRkviOgYP\njFluUJUjERGRZlHREHl3/4KZnQ/sBbwLeA24zd2fSjI4kbzsmA5GdLT3ektsRGc7m48eWsOoREQk\nzSpKggDc/Rl060tqJJPJMGn3cUyZ9miPnaMzGZg0cZzmCxIRkdgqnSyxjdAJejSwTvF+d7+yn3GJ\nrGGCDWfyAdsy9fbZLOgqmCeos51JEzVPkIiIlKeSyRLHA9cSlsvo6Wt3Dqh6EmRmxwNfBkYBjwAn\nuvv9JcqOIiwAuyMwDrjA3U/podwk4AxgE8Iot1Pd/aaqVEAqMsGGMz47jFlzulm0ZBkdgwex+eih\nagESEZGyVTI67CJgEfARYCTQWfSzQWLRlWBmBxOSmtOBHQhJ0M1mNqzEIYOABcCZwMMlzvk+4CrC\n6Lf3Ejp6TzOzrZKNXvork8lgYzvZecuRWjJDREQqVsntsK2BSdHK8vVyMnBx/rabmR0LfAw4Cjin\nuLC7Px8dQzS0vydfAG5y9/Oix982s72AE4DJyYYvIiIi9VZJS9AsVs0PVHNmtjYwgbBuGQDungNu\nBXbrx6l3i85R6OZ+nlNEREQaVCUtQScDF5jZI+7+ZNIBxTAMaAPmF22fT//WLRtV4pyjyj1RW1sl\nuWXjyddD9Wk8zVQXUH0aWTPVBVSfRlaPOlSSBF1ISAweM7O5QHfR/py7b9/vyFJsyJD2eoeQKNWn\ncTVTXUD1aWTNVBdQfSSoJAmaSRgBVi+vACsInbILjQTm9eO885I65+LFS1mxYmU/QmkMbW0DGDKk\nXfVpQM1UF1B9Glkz1QVUn0aWr0stlZ0EufsRVYijnOd/28xmAnsA1wOYWSZ6/NN+nHpGD+fYK9pe\nlhUrVrJ8ebr/GAupPo2rmeoCqk8ja6a6gOojQcUzRtfZecDlUTJ0H6Gf0rrA5QBmdhawkbsfnj/A\nzLYnzGs0GBgePV7m7k9ERS4AbjezU4AbgEMIHbA/V5MaiYiISE2lsieVu19NmCjxDOAhYDtgb3fP\nL+g6ijCZY6GHCLfyxgOHAg8Skp38OWdE248hzCX0CWB/d3+8ejURERGReklrSxDRavU9rljv7kf2\nsK3PhM/d/wT8qf/RiYiISKNLZUuQiIiISH8pCRIREZGW1O8kyMw+Y2adSQQjIiIiUiv9SoLMrA34\nNbBpMuGIiIiI1EYSt8O0hLeIiIikjvoEiYiISEvqbxK0EriCsJSFiIiISGr0a54gd88Ba8zJIyIi\nItLodDtMREREWpKSIBEREWlJSoJERESkJSkJEhERkZakJEhERERaUqwkyMwmmNmrZrZvL2X2NbNX\nzGz75MITERERqY64LUFfBO529xtLFYj2/Qs4JYnARERERKopbhI0EfhtjHK/Bz5ScTQiIiIiNRI3\nCRoBvBSj3EtRWREREZGGFjcJ6gbeHaPcu4FFlYcjIiIiUhtxk6AZwNExyh0F3FV5OCIiIiK1EXft\nsB8Dd5jZZcCX3f21wp1m1hGV2QP4cLIhioiIiCQvVhLk7v8ysxOB84FDzOwB4AUgB4wFdozOdaK7\nqyVIREREGl7syRLdfQoh2bkKGAUcCHwC2BD4HTDB3S+qRpAiIiIiSYt7OwwAd/838foGiYiIiDQ0\nLZshIiIiLSlWS5CZ/aOX3W8DC4A7gN+6+5tJBCYiIiJSTXFbghYT5v/p6ectYEvgIuBBM9NkiSIi\nItLw4o4OO6CvMma2CXA78H3gc/2KSkRERKTKEusT5O7PAd8DSq40LyIiItIoku4Y/TQwLOFzioiI\niCQu6SRoM+CVhM8pIiIikrjEkiAz2xj4FnBjUucUERERqZa4Q+Sv72V3G2EG6e0It8O+kUBcIiIi\nIlUVd8boIYR1wnqyHHDgEuA37v7fJAITERERqaa4Q+QnVjkOERERkZoqa+2w3phZBtgTOMzdj0jq\nvCIiIiLV0O8kyMx2Ag4DDgZGEpbQEBEREWloFSVBZrY5IfE5FHhPtPnvwBTgpmRCExEREame2EmQ\nmY0CPk1IfsYTOkrfQUh8zgXOcvc7qxGkiIiISNJizRNkZrcAcwjJDsCXgTHuvgfwayBTnfBERERE\nqiNuS9Ae0b+3AN9x9xlVikdERESkJuImQZ8k9P/5GPAvM3sO+D1wFfBSVSITERERqaJYt8Pc/c/u\nPokw+uto4Bnga8CjwAxC/6Ch1QpSREREJGllrR3m7q+7++XuvhcwGjgFeJ3QJ+jPZjbdzI5IPkwR\nERGRZFW8gKq7z3f3C9x9F2Bz4AxgQ+BXSQUnIiIiUi2JzBjt7k8TkqAzzGx8EucUERERqaaKW4JK\ncfcHkz6niIiISNIST4JERERE0kBJkIiIiLSkxFaRF2kGuVyOWXO66X5jGR2DB5Id00EmownRRUSa\nkZIgkchMX8jU6bNZ0L30nW0jOtqZtPs4JtjwOkYmIiLVUOkq8msDRwC7EIbFvwzcA1zh7m8nFp1I\nCUm32Mz0hUyZ9ii53OrbF3QvZcq0R5l8wLZKhEREmkzZSZCZZYG/AWOBR4D5wA6EpOgbZvY/7u5J\nBlkijuMJC7mOiuI40d3v76X8RMICsFsDLwDfd/crCvYfTlgMNseqBWHfdPd1q1IBqVjSLTa5XI6p\n02evkQCt2g9Tb5/N+Oww3RoTEWkilXSMvhhYBpi7T3D3fd19ArAF8CZwUZIB9sTMDiYkNKcTErBH\ngJvNbFiJ8psAfwVuA7YHLgAuNbO9ioouIiRV+Z+NqxG/VC7fYlOYAMGqFpuZvrDsc86a073G+Yot\n6FrKUy8uKvvcIiLSuCq5HbYL8P+iCRLf4e6zzezbwBU9H5aok4GL3f1KADM7lrC461HAOT2UPw54\nxt2/mg/XzD4QneeWgnI59wo+RaUmqtVi0/3Gspjl3op9ThERaXyVtATNJdwy6kkOmFd5OH2L+iNN\nILTqAODuOeBWYLcSh+0a7S90cw/lB5vZc2b2gplNM7OtEgpbElCtFpuOwQNjlhtU1nlFRKSxVdIS\n9F3gTDN72N2fyW80s82ifd9NKrgShgFthL5IheYDVuKYUSXKDzGzQe7+FuCElqR/A0OBrwB3m9lW\n7j63nADb2ppj+qV8PRqlPq8vjdfnfvF/l7HWWmvGXKo+W226ASM621nQVTrBGtnZzpabdDZMn6BG\nuzb9pfo0rmaqC6g+jawedYiVBJnZ9UWbOgi3lB4DFgAjgG0IicUnqc0tsUS5+z2EEW4AmNkM4Ang\n84S+R7ENGdKebHB11ij1GbPh0Fjlxm7UQWfneiX391Sfz+6/DWdfcT8re2jjHJCBo/ffhg02GBw7\n1lpplGuTFNWncTVTXUD1kSBuS9AQVr8FNiv6ARgIdAP/ih6vn0xoJb0CrABGFm0fSelbcfNKlF8c\ntQKtwd2Xm9lDwLhyA1y8eCkrVqws97CG09Y2gCFD2humPht1rhOrxWbDjkF0dS1ZY19v9dli9FBO\n+OR2/PG2p5hfcP6Rne0cvMfmbDF6aI/nrJdGuzb9pfo0rmaqC6g+jSxfl1qKlQS5+8QqxxGbu79t\nZjOBPYDrAcwsEz3+aYnDZgD7FG37aLS9R2Y2ANgWuKHcGFesWMny5en+YyzUSPWZNHFcj/P5AGQy\ncNDEcaxYkaN0t7XS9XnvuGFs/553MWtON4uWLKNj8CA2Hz2UTCbTMPUv1kjXJgmqT+NqprqA6iNB\nWmeMPg+4PEqG7iOM8loXuBzAzM4CNnL3w6PyvwCON7MfApcREqaDgH3zJzSzbxFuh80m3O77KmEu\npEtrUB+JaYINZ/IB2zL19tmrtQiN6Gxn0sT+z+ycyWSwsZ39DVNERFKgkskSv93L7pWEuXYedvd/\nVhxVH9z96mhOoDMIt7UeBvYuGN4+ChhTUP45M/sY8BPgC8CLwNHuXjhirBO4JDq2C5gJ7ObuT1ar\nHlKZCTac8dlhPbbYiIhIfK2+XmImV2rSlRLMrIvQDyh/4+5NYJ3o/0uBtQmjtx4E9m3BeXdyXV1L\nmqJZcq21BtDZuR6qT+NpprpAdepTzzf3Zro+zVQXUH0KNdp6iVFdapqBVXI77CPAHwlD4a9z9zfM\nbDBwIPBt4DOEW1O/BX5EWE5DRKRmGu3NXaTRaL3EoJJB+T8HznX337n7GwDu/oa7/4awlMX57n4b\n8D3W7IwsIlJV1VhaRaSZxJ19v9w7RWlUSRK0A/B8iX3PEUZUATxGmHRQRKQm9OYu0jetl7hKJUnQ\n88BnS+w7hlUJ0rsIc/qIiNSE3txF+qb1EleppE/QacDVZuaEldkXAsOBjwObAZOicnsAdyYRpEgz\nafXRGNWkN3eRvmm9xFXKToLc/c9mtjMhGToQ2BB4GbgfONjdH47KHZ9koCLNQB12q0tv7iJ9y47p\nYERHe6+tpiM629l8dPP3aKloskR3fwj4VMKxiDQ1jcaoPr25i/Qtk8kwaffeZ9+fNHFcS7RQl90n\nyMy26WP/fpWHI9Kc1GG3NvJv7qXeu1vpzV2kN/nZ90d0rr5W14jO9pb6QlZJS9ADZvZNd/9x4cZo\nrqCfEeYJaksiOJFmUU6H3eyYjhpF1ZyqvbSKSLPQ7PuVJUHfAb5nZh8HDnf3581sIvBrwiSJn0gu\nPJHmoA67tVXPN/dcLseTz3fx9nNdrJ2B92w0pKU+VCRdWn29xEo6Rp9tZjcBvwH+Hf3/IMKK7p9v\nwWUyRPqkDru1V483d3V8F0mXSuYJwt0fAT5PWEPsU4QFTA9TAiTSs3yH3d6ow266aaZqkfSppGN0\nxsy+AUwHZgDHApsAD5nZLsmGJ9Ic1GG3uanju0g6VdISdDfwDeBUd/+Iu18CbAc8C/zTzL6XZIAi\nzUKjMZqXZqoWSadKOkavBYx39yfzG9x9LrCPmR0LnAN8M6H4RJqKRmM0J3V8F0mnSpKgXd19RU87\n3P0XZvb3fsYkZdIyDOnS6qMxmpE6voukUyWjw3pMgAr2P1N5OFIujUYRqT/NVC2SThWNDpPGoNEo\nIo1BHd/7lsvl8Be6uPfx+fgLXeokLg2horXDpP7ijkYZnx3W0m+8IrWimapLU4u1NColQSmlZRhE\nGk++4/vTcxezPJdh7QE5NtuwtWeM1sLB0siUBKWURqOINKZMJsMWG3fS2bkeXV1LWL58Zb1Dqhu1\nWEuj61efIDMb28O2fftzTolHo1FEpNFp/iRpdP1tCXrOzJ4CzgMuAY4AfgHok7fKNBpFRBqdWqyl\n0fV3dNgHCKvHfxd4HLgU+Hl/g5K+aTSKiDQ6tVhLo+tXEuTud7v72cAUwICXgK8nEZj0TcswiEgj\n08LB0uhi3Q4zs0uA7dx91x72/RD4EnAKYTHVLwHfTzJIKU3LMIhIo8q3WPc0OizsV4u11FfcPkEf\nBc4o3GBmAwi3vw4D/p+7/97MlgInoSSoprQMg4g0Ks2fJI0sbhI0HHgu/8DMBgFTgY8A+7n7zdGu\nWcCmSQYoIiLpphZraVRxk6AngWPN7F/AZsDlwDhgD3e/t6Dc5sDiRCMUEZHUU4u1NKK4SdCpwDRg\nCaEz9X+BLmDdfAEz2wT4BqBV5EVERKThxUqC3P0WM9sG+B9gJfBnYDfgRjN7AngdmBD9+40qxSoi\nIiKSmNiTJbr7s8BFBZuuM7OdgeOBTQiTJZ7r7i8lGqGIiIhIFfRrxmh3f5QwLF5EREQkVfo7Y7SI\niIhIKikJEhERkZakJEhERERaUn9XkReRlMnlcsya0033G8voGDyQ7JgOTVonUoJeL81NSZBIC5np\nC5k6fTYLuguWL+hoZ9LuWr5ApJheL82v7NthZra9me1bYt++ZrZd/8OSQrlcDn+hi3sfn4+/0EWu\np5UIJfWSvM49nWumL2TKtEdXe0MHWNC9lCnTHmWmL+xvFUTqKsnXkF4vraGSlqCfAHcBN/awb2fg\nZGCv/gQlq+ibSGtI8jqXOtdby1b0uJI3QC4HU2+fzfjsMDX1Syol+RrK5XJMnT67KV4vup3Xu0qS\noPcC55TYNwM4sfJwpFD+m0jxCzH/TWTyAdsqEWoCSV7n3s7VlwVdS3nqxUVkx3TEDV2kIST9Xjlr\nTnefr5k0vF70JbpvlYwOGwQM7GXfOpWHI3lxv4no1li6JXmd+zpXHN1vvFX5wSJ1UI33yu43lsUs\n17ivF90d0xlxAAAgAElEQVTOi6eSJOgh4DMl9n0GeKTycCSvnG8ikl5JXuc45+pLx+BB/TpepNaq\n8V7ZMbjU9/zico35etGX6PgquR12FnC9md0A/BqYC2wEHAnsDeyfXHitqxm+iUjfkrzOcc9VyojO\ndjYfPbRf5xCptWq8V2bHdDCio73X5KqRXy/NcjuvFspuCXL3G4BDgW2Bq4F/Rv9uCxwa7Zd+Svs3\nEYknyesc91w9yWRg0sRx6jApqVON98pMJsOk3cdR6uXQ6K8XfYmOr6IZo939j+4+FtgS+CCwpbuP\ndferE42uheW/ifSmkb+JSDxJXuc45xq63kCGd6zebW9EZ7s62UtqVeu9coINZ/IB2zKic/Vzp+H1\noi/R8fV3FXlPKhBZXf6bSE8jHsL+xv4mkla1Hk6a5HWOc67/+6gxPjuMWXO6WbRkGR2DB7H56KH6\nO5LUKvc1lMvleOzpV5jz8iLWb1+719f4BBueytdL2m/n1VKmko5RZjYGOAAYw5qjwXLuflICsaVV\nrqtrCcuXr0zkZDN9IVNvn82CroIhjp3tTJpY/SGOa601gM7O9UiyPvXUV33qOZy03OvcW12S/pup\nRWLYan9raZKWusT5u++xTMqHjJe6PqWmDcjbZ5exTNp9XI2ijCeqS00zzLKTIDP7FPAbwq20BUDx\nzcecu2+WTHiplGgSBKs+hGr9TaStLcPcrjdjfWNKg74Sh96+Sdai+buc69zXB1NSfzO1SgzT8kEb\nV5L1qfdkd2m6Nr393dfiNV6La1X8HFttugEbbDC4x+szdfpsbrr3hR7PU6v3tXLUIwmq5HbYD4Bp\nwDHurvHZNZDJZLCxnTV9zmb8xlRKo8wOm+R1TuJcmqyz/jTZXXlK/d3X4jVei2vV43N0tvPZ/bdh\ni6JbW/mlckpJ06zX1VRJx+jhwCVKgJrXO5Nsda05ydbP//woDzy5oE6RVYfmZFqT5hmpP012V57e\n1g2r9mu8Fteq5HN0LeXsK+5f431Z72vxVNIS9DdgV+C2hGMpi5kdD3wZGEWYoPFEd7+/l/ITgXOB\nrYEXgO+7+xVFZSYBZwCbALOAU939pmrE36jizDp88fX/IZOBCTaidoFVUSsOJ+2r2V7zjNRXo7RO\npkVfrTDVfI3X4lr19Rwrc/DH255i+/e8653naMX3tUpUkgQdC/zRzNYlJELdxQXc/cH+BtYbMzuY\nkNAcA9xHWLT1ZjPLuvsrPZTfBPgrMIUwx9GewKVmNtfdb4nKvA+4CvgacANwGDDNzHZw98erWZ+8\net/7h3gffitW5pgy7bGmuR3SasNJ4zTb6w20vpSExhfntm01X+O1uFZxnmN+0XO02vtapSpJgtYH\n1gVOA04t2pcBckBbP+Pqy8nAxe5+JYCZHQt8DDiKnhd3PQ54xt2/Gj12M/tAdJ5bom1fAG5y9/Oi\nx982s72AE4DJ1anGKo1y7z/uh18zfRNtpeGkcfv56A20vpSExhO3FeYHn9ulaq/xWlyrSp6jld7X\n+qOSJOhKYCxhtfhZrDk6rKrMbG1gAqGDNgDunjOzW4HdShy2K3Br0babgZ8UPN6N0LpUXKasZUDu\nffFeFr++lBUr4o+iePL5bv50x9PkYLX0set1+P71j/DJD7+HLTauzbe9l95+na62WbHKdi2GaY++\nydiRg6scVTLa2gYwZEl7j9dn2/FvrLoGRTLAHju8hwcXPFCTOOPorS6l5HIw5R+P0TWg9Jvxz6c/\nz+Sh24Qlkoc+T1cvb9yd6w9i8drrM3N+udGvqZL6NLL+1ifu6/CltzPMnN/z6J+kNPK1eX7e6/jr\ns3r92t21GK577E22Hb+8Kq/xWlyrSp8jje9re3VOrOlzVpIE7UxYHmNa0sHENIzwJ1/81jsfsBLH\njCpRfoiZDXL3t3opM6qc4Hb91a7lFF9lvdK7/vUAUMu/015iKXbXv6oXRs010jWopt6u70r467UV\nlpVkxXgdNtXrr1Ll/J6q9RqvxbWq9DlS9r6WO722gy0qGR32FP2caVpERESk3ipJZk4Bfmxmj7n7\nk0kHFMMrwApgZNH2kcC8EsfMK1F+cdQK1FuZUufs0T1H38OSJW+yYmW8bPaxZ17lT3c802e5T354\nM7bZ7F3lhNIvTzz3Gtfc/jS9VWOD9Qdxwie3TU2foLYBGdZbb52yrk+jqqQuz7/8Opf/re+X7JH7\nbMHYUeu/8ziXy/HCvDd4fekyhqw7kDEjB5d9zQvPsX77QMaOWv0ccerT1zkaSVJ/a08818WtD8zh\ntddX3ZbcYP1B7LnjGLbcpDZzhzXy6yaXy/GzPz1K1+ulb9sWv09Vqz6lrtWWG3dy92PzSt6SmrT7\nuHeu5RPPdXHLA3NWq0/n+oPYK7rePT7HkEHs98HN2GzU+g13fcrVNqD2r+dKkqDzCbeIHjOzuaw5\nOizn7tv3O7IS3P1tM5sJ7AFcD2BmmejxT0scNgPYp2jbR6PthWWKz7FXUZk+7TJ6l7JmVm3/bxf/\nWNH3Zdh5w/Fkh9VuFMh7h8EWQ9/LhdeWnmH1uInbsO7Stes6mq0caZr5ti+V1GX7d+WYcdegPjtK\n/u/Wu65xHXfoR9/8VZ3+VxLeclYyouPt1Tr9x1/SpPQ5GklSf2vvHQafnlCfGePzGv11c/zuG/c+\nE/Tu27LD8FV/I9WqT0/Xaty7h/D1S+6lY8WQksc9MrOdT08Yz4OzXuHW2xZBbmNWS2+74dbbIHvA\nWA7ZccIaz7HlJp0lZ4xOm7XWqmhN9/49ZwXHzIQek9paOg+4PEqG8kPk1wUuBzCzs4CN3P3wqPwv\ngOPN7IfAZYRk5yBg34JzXgDcbmanEIbIH0LogP25alakkXvw77TlSE47fB1+dd1jzC9aj2dCdjjX\n3P503UezSXz1WJQ3iVmnW33m6nrMGJ8m+dXe67XGYqHia+UvdMUaPj9rTndZcw0VPkcjf/FMg7KT\nIHc/ogpxlBvD1WY2jDCx4UjgYWBv93em5RxFWNw1X/45M/sYYTTYF4AXgaPd/daCMjPM7FDg+9HP\nU8D+1Z4jqNFXi99t242wdw/h8Wdfe+ebx+v/XcaUaY+17IdSmtXyA6OcSeSSOIc+DFpXNVd778/8\nbXGHtj/xfLxkSfNCJa/sJMjMLgPOdPdne9i3MXC6ux+VRHC9cfcphMkPe9p3ZA/b7iS07PR2zj8B\nf0okwDI00jeZnhR+88jlcpx28T36UEqxan5gFCpnErmtNt2g3+fQh0Nrq0aLWX/nb4s731ZcrT4v\nVDVUcjvsCMLtpTWSIMLw9cMJkxZKGWr1wdRf+lBqDrW4xZLEJHKaNFDqJYnbsHG7O2wxtoPr7+o7\nJk1OmrxKeyGV6hO0OfBqhedsefkPpp23HNmwnYz1obSm3hZubGVJzDqtmaulHpJaQDjf3aHUW3m+\nu4ON7WRER3uv59LsztURqyXIzI4jLD0BIQG6ysyKU9t1CAuPTk0sOmk4+lBaXaMsd9KIkuj038gD\nB6R5JdniHbe7QyP3DW1mcW+HzSWMCgPYBnBgYVGZZcATwK+SCU3KVYsFWPWhtEqrj1rqSxKd/ht9\n4IA0p6RbvON0d2j0vqHNKlYS5O7XAdcBmBnAGT11jJb6qVWLhD6UAo1aiieJN3Z9OEitVaPFO04/\nvLT0DW0mlQyRf2fkVTRJ4YbAAndfnmRgEl+tWyT0oaQO4uVI4o1dHw5SS/Vs8da8ULVV0RpgZrY3\n8F1gh+gcOwEPmtklwB3u/rvkQpTe1KtFotU/lNRBvDxJvLHrw0FqRS3eraPs0WFmdghwI2GI/GTC\n8id5TwNrzNEj1VNOi0TS0jCarVrUQVykueVbvEd0rj5qa0Rne8v392smlbQEfQs4392/ZGZtwC8L\n9v2HsISF1IhaJOpDHcRFml+rt3i3gkrmCdqM0BLUkyWA3vVrSC0S9RF3/g+9WYqkWyu3eLeCSpKg\necAWJfZtBzxfeThSrnyLRG/UIlEdai4XEUm3Sm6HXQV8x8yeBG6PtuXMbBvgq8BFCcUmMagDX32p\nuVxEJL0qSYK+A2wN3MKqJTJuAoYDfwXOTiQyiU1D1utLo5ZERNKpknmClgH7m9nuwF6ERVNfA251\n91sTjk9iUouEiIhIeSqaJwjA3acD0xOMRfpJLRIiIiLxVZwEmdlGwGjCwqmrcfc7+xOUiIiISLWV\nnQSZ2WbAb4Bdo03F91tyQFs/4xIRERGpqkpagn5JaAE6CnicsHq8iIiISKpUkgTtDBzu7tcmHYyI\niIhIrVQyWeJLwIqkAxERERGppUqSoG8Ap5rZBkkHIyIiIlIrldwOO4LQJ+g5M3sY6C7an3P3/fsb\nmIiIiEg1VZIEDQZmFzxeP6FYmloul2PWnG6631hGx+CBWohPRESkziqZMXr3agTSzGb6QqZOn82C\n7oIlLTrambS7lrQQERGpl0r6BEkZZvpCpkx7dLUECGBB91KmTHuUmb6wTpGJiIi0NiVBVZTL5Zg6\nfXaPq7uH/TD19tnkShUQERGRqlESVEWz5nSv0QJUbEHXUp56cVGNIhIREZE8JUFV1P1GvMm0u994\nq8qRiIiISDElQVXUMXhgzHKDqhyJiIiIFFMSVEXZMR2M6GjvtcyIznY2Hz20RhGJiIhInpKgKspk\nMkzafRylpgPKZGDSxHGaL0hERKQOlARV2QQbzuQDtmVE5+otQiM625l8wLaaJ0hERKROKpkxWso0\nwYYzPjuMWXO6WbRkGR2DB7H56KFqARIREakjJUE1kslksLGd9Q5DREREIrodJiIiIi1JSZCIiIi0\nJCVBIiIi0pKUBImIiEhLUhIkIiIiLUlJkIiIiLQkJUEiIiLSkpQEiYiISEtSEiQiIiItSUmQiIiI\ntCQlQSIiItKSlASJiIhIS1ISJCIiIi1JSZCIiIi0JCVBIiIi0pKUBImIiEhLUhIkIiIiLWmtegdQ\nLjPrBC4EPg6sBP4EnOTuS/o47gzgs0AHcBdwnLvPLth/O/ChgkNywMXuPjnRCoiIiEhDSGNL0FXA\nlsAewMcIicvFvR1gZl8DTgCOAXYGlgA3m9nAgmI54BJgJDAK2BD4atLBi4iISGNIVUuQmW0B7A1M\ncPeHom0nAjeY2ZfdfV6JQ08CznT3v0bHfAaYDxwAXF1Q7r/uvrBqFRAREZGGkbaWoN2ArnwCFLmV\n0IqzS08HmNmmhJad2/Lb3H0xcG90vkKHmdlCM3vUzH5gZu2JRi8iIiINI1UtQYRkZkHhBndfYWav\nRftKHZMjtPwUml90zO+A54G5wHbAOUAWOKjcINva0pZb9ixfD9Wn8TRTXUD1aWTNVBdQfRpZPerQ\nEEmQmZ0FfK2XIjlCP6CqcfdLCx7+x8xeBm4zs03d/dkyTpUZMqS5GpBUn8bVTHUB1aeRNVNdQPWR\noCGSIODHwK/7KPMMMA8YUbjRzNqADaJ9PZkHZAgdngtbg0YCD/V4RHBfdNw4oJwkSERERFKgIZIg\nd38VeLWvcmY2A+gwsx0K+gXtQUhW7i1x7mfNbF5U7t/ReYYQ+hD9vJen24HQAvVy3HqIiIhIemRy\nuVy9YyiLmd1IaA06DhgIXAbc5+7/r6DMk8DX3P266PFXCbfbjgCeA84Etga2dvdlZrYZcChwIyEZ\n2x44D3jB3T9Sm5qJiIhILaWxJ9WhwJOEUWF/Be4EPl9UZnNgaP6Bu58D/Iwwn9C9QDuwj7svi4os\nA/YEbgaeAH4ETAX2q1otREREpK5S1xIkIiIikoQ0tgSJiIiI9JuSIBEREWlJSoJERESkJSkJEhER\nkZakJEhERERakpIgERERaUkNMWN0ozOzDwJfASYAGwIHuPv1RWXOAD4LdAB3Ace5++yC/YMIEzAe\nDAwizEk02d1XWxC22szsNOBAYAtgKXA3YWLJWUXlGr4+ZnYsYdLMTaJN/wHOcPe/FZRp+HqUYman\nAj8Aznf3Uwq2p6JOZnY6cHrR5ifdfauCMqmoSxTLRsAPgX2AdYGngCPd/cGCMqmoj5k9C2zcw66f\nu/uJUZlU1CWKZQDwXeAwwsLYc4HL3f17ReVSUSczGwx8DziAMDnwg8AX3f2BgjINWZdafV6aWSdw\nIfBxYCXwJ+Akd19STrxqCYpnPeBhYDJhKY3VmNnXgBOAY4CdgSXAzWY2sKDY+cDHgE8CHwI2Ily0\nWvsgYeLIXQgTRK4N/N3M3ll9L0X1mUOYCXw84QX3D+A6M9sSUlWPNZjZToS4HynanrY6PUZYp29U\n9POB/I401cXM8m/WbwF7ExZ0/hLQVVAmNfUBdmTVNRkF7EV4b7saUlcXgFMJk+ZOJnzB+yrwVTM7\nIV8gZXX6FWGpp8OAbYBbgFvNbENo+LrU6vPyKsLrcI+o7IcIEyKXJ5fL6aeMn2w2uzKbze5XtG1u\nNps9ueDxkGw2uzSbzX6q4PFb2Wz2wIIyFp1r5zrXZ1gUxweapD6vZrPZI9Ncj2w2OzibzXo2m/1I\nNpudns1mz0vjtclms6dns9kHe9mfprqcnc1m7+ijTGrq00Ps52ez2VlprUs2m/1LNpv9ZdG2a7LZ\n7JVpq1M2m10nm82+nc1m/6do+wPZbPaMlNWlKp+X2Wx2y+jxDgVl9s5ms8uz2eyocmJUS1A/mdmm\nhG9St+W3uftiwvIcu0WbdiTceiws48ALBWXqpYOQrb8G6a2PmQ0ws08TblPcndZ6RH4O/MXd/1G4\nMaV12tzMXjKzp83st2Y2BlJZl/8FHjCzq81svpk9aGafze9MYX3eYWZrE1ocfhU9TmNd7gb2MLPN\nAcxse+D9hPUg01antYA2QqtjoaXAB1JWl9UkGPuuQFfBQuoQltLKEe5yxKYkqP9GEX7x84u2z4/2\nQbgdsCy62KXK1JyZZQjNjv9y98ejzamqj5ltY2avE94wpgAHRi+YVNUjL0rk3guc1sPutNXpHsKi\nxXsDxwKbAnea2Xqkry6bEfqfOfBR4CLgp2aWX7g5bfUpdCBhrcUrosdprMvZwB+BJ81sGTCT0Jfu\nD9H+1NTJ3d8AZgDfMrMNoy94/0dIADYkRXXpQVKxjwJW69vk7isIX+bLqp86Rre2KcBWhG9MafUk\nsD3hTfwg4Eoz+1B9Q6qMmY0mJKV7uvvb9Y6nv9z95oKHj5nZfcDzwKcI1y1NBgD3ufu3osePmNk2\nhOTuN/ULKxFHATe5+7x6B9IPBxMW1/408Djhi8QFZjbX3dN4ff4PuAx4CVhO6Bh9FaHvoyRILUH9\nNw/IELLXQiOjffkyA81sSC9lasrMLgT2BSa6+8sFu1JVH3df7u7PuPtD7v4NQkfik0hZPSITgOHA\ng2b2tpm9DXwYOCn6djuf9NXpHe6+CJgFjCN91+dl4ImibU8AY6P/p60+AJjZWMIAiV8WbE5jXc4B\nznb3qe7+H3f/HfATVrWopqpO7v6su+9O6GQ8xt13BQYCz5CyuhRJKvZ5hFFz7zCzNmADyqyfkqB+\ncvdnCb/0PfLboou3C+E+NYSm2eVFZYzwBjqjZsGueu4Lgf2B3d39hcJ9aaxPkQHAoJTW41ZgW8K3\n2O2jnweA3wLbu3v+DTBNdXpHNOx3HDA3hdfnLsCKthmhZSvNr5ujCMn1jfkNKa3LusCKom0riT7j\nUlon3H2pu8+PhoPvDUxLa10g0eswA+gwsx0KTr8HIcG6t5yYMrncGiPYpEjUh2Ec4Rf8IHAKMB14\nzd3nmNlXCUO1jwCeA84Etga2dvdl0TmmEOYXORJ4HfgpsNLdP1jjukwBDgH2I3wrz1vk7m9GZVJR\nHzP7AXATocPc+oTOnV8BPuru/0hLPXpjZtOBh/LzBKWpTmb2I+AvhETh3YR5XLYDtnL3V1NWlx0J\nidB3CMPIdyEMx/1cvt9JmuoTxZIBngV+F7WiFu5LW11+TfgQPJYwX9h4wvW51N2/HpVJTZ3M7KOE\nzxsHNie0dP0X+JC7r2jkutTq89LMbiS0Bh1HaCW7jHDLOt9PLxb1CYpnR8JFzEU/50bbrwCOcvdz\nzGxdwouuA/gnsE/+gkZOJnxTuYYw+dPfgONrE/5qjiXU4fai7UcCVwKkqD4jCNdgQ2AR8G+iBAhS\nVY/erPYtJWV1Gk3ox/AuYCHwL2BXd38V0lUXd3/AzA4kdMD9FiF5OKmg422q6hPZExgD/Lp4Rwrr\ncgLhw/TnhPeFuYTO62fmC6SsTkOBswhfHl6L4vlm1Pm30etSq8/LQwmTJd5KaPW7htAVoixqCRIR\nEZGWpD5BIiIi0pKUBImIiEhLUhIkIiIiLUlJkIiIiLQkJUEiIiLSkpQEiYiISEtSEiQiIiItSUmQ\niIiItCQlQSIiItKSlASJtBAz+46ZvV7vOHpjZieb2fNmttzMrq13PBKPmQ01s9PNbIt6xyISl9YO\nE2kt+fV8GpKZjQN+TFg36S/Aq/WNSMrQAZwOPAo8WedYRGJRS5CIJMbM1unnKfKtCJe6+73uPru/\nMaVRAr/HesjUOwCRcqklSKQGzOxyYAJhteufAFngP8Bx7v5gVGZjwurkB7n7tQXHng/s7+6bRo+P\nAC4DdgJ+AHwAmENYZfkfhJWzPxsdfpm7f72HeHYkrLi9XfScX3H3G4rKfIywYvp2wBuEVZq/7O7/\njfZ/mLBa9MeBI4GPAncA+5X4HQwitPAcDGxAaC34rrtPi/b/Gjic0FL1jJnlgCPd/coeztWv30F0\ny+aHwIcJ74O3A19w92cKypwCfJpwrd4C7gNOcfenCspsRWi52hloj2K41N1/HO2/HVjs7vsVHLM9\n8BAw0d3vjLatBE4DOqPfwbqElcQxs92A7wG7AMuBG4AvuvvCaH/+7+YzwPujmJcBZ7v7T8zs08B3\ngA0JK24f6e6LC+LJr1h+QHRdHgNOc/dbCspMJ/wNXA58n7C6+X3A59z9mSiGZwjX7hozI/r/pu7+\ngpmdChwNjAZeBx6Ojn0ekTpSS5BIbeSAUcAFhA/fScA6wLVm1hbj2FzRY4ArCLeMDgBeAq6Nzv9u\n4P8BFwKnRh+ChQYCfyB8oB0IPBXFsXW+gJkdBFwHPBKd/yvAJ4BLe4jvYmB2VO7HvdTjKuBzwNnA\n/oQk8E9m9vFo/xnA16L/HwDsRvjA70nFvwMz2xS4m3D75jPAIcBw4FYzW7vgOUYDU6JzH01o6bjb\nzDoKyvyVkKwcCewL/AhYr4c4S8Vf6AvA5sBRwP9Fse5GSDS7gE8Rfn87AdN6OP57wH+Bg4CrgXPN\n7AfAicCXgcnAR4BzCn4XaxMSo30JSdj/Ao8DNxT+PUTeG53na4REbRzwm2jfy4S/jwxwKrAr4fq9\nbGafIVzbXwJ7E36XDwNDSvxuRGpGLUEitdMJfNDdnwQws/8SWi12IXwol+un7n5JdK65hL4YE9z9\n/dH+W8xsf0LC9YeC49YGznT3K6Jj/05IhL4OHBaV+RHwe3f/fP4gM3sZuMnMznT3JwrOd527n9Zb\noGa2LSHhOsbd84nU36OE5HTgr+7+rJnNivY97O4vVOl38B1CX6M93f3t6NgZhJaMo4FfALj7KQXx\nDwBuA+YTkoxLzexdwCbAiQWtaHfEiBl6vnX0qrt/smjb2cB97n5QQSyPAY+Z2f+4+98Kyt7t7l+K\nykyP4jwBGOvu3dH29xKSrGOjY/6P0NK3nbt7tO0WM9uc0ApYmEAPBbZ399eic60PXGZmG7n7XDN7\nKCo3293vK4h3J+ARdz+n4Fx/Kf2rEakdtQSJ1M7cfAIUeZzwYTi6gnPlCN/g8/LJw21F5WYBY3o4\n/p2WBHdfGT3eBcDMssDGwFQza8v/AP8EVgI7Fp3rxhjxfjCK+Zqi7X8EdjCz9hjnKFbp72Av4Hpg\nZUHdugm3qHbKFzKzXc3sFjN7hXAbagmhlScL4O6vAs8DZ5vZZ8zs3RXUoVBhQkP0O3kf4fZS4XV4\ninDbbaei49/5XUTX9BlCMtldUGYW0GFm60aP9yIkjrMLnmMt4JYezv9wPgGKPB7929ff74OEa3yu\nmb0/Or9IQ1ASJFI73UWPl0X/VtoJ9p3z5Vs0SjxH8fnfdvdFRdvmE/qMAAyL/v0z8HbBzxLCe0Zh\nQpGLju1LZ/S8xfHNJySCHWseEkslv4NhwBdZvW7LCP2KxgCY2Rjg5ii2YwjJyI7AwqJz7UVIBi4E\n5pjZ/Wb2wQrrUvx77ATaCH3IimMdw5rJbU/17utvbhgwvofzf5M1k5uezpWh77/fy4GTCX3G7gQW\nmtn5UR8xkbpSRi7SON6M/h1YtL0z4edZ28yGFiVCIwn9OgDy3/aPJ3R+LTa36HGcIfevlXjeUdHx\nxR+w1fQaoS/Pz1nztlR+DqV9CK0+B7r76wBRK8wGhYWj0WsHR/veR+hgfL2ZvTvqQP4mPV/Pnn5n\nxdu6o23fp+c+QK+UqmAZXiP0+zqKKo3ucvcc8DPgZ2a2IeEW2w8JCeX3q/GcInEpCRJpHAsI38S3\nzG8ws4GEEUxJz+1zIOEber6/ywHADAB3f9LMXgTe4+6/SOj5/kX4kJ3E6p2rJwEPufvShJ4njluB\nbQi3d0r9Xtch/M6XF2w7mBLvme6+AvinmZ1N6FC+EaGz+IvAnkXF944TpLv/N+qrtKW7fzvOMRW4\nlZDwvezu8/p5rj5bNt39ZeAnZnYYBX/nIvWiJEikQbh7Lpoh+QQze5rwTf8EQvKQZBL0NvDNqM/J\ns4QWn9GEVoy8U4DfmdlgwgitJYROwPsShk/n5++J1Xrg7o9GdTsv6o/ihNFbu7LmkPpqzzdzOqGF\n6+9mdgnhNtQoQrJ5p7v/kdBhPQNcbmYXE5KmUwijtIB3OnufS+jX9DThlt6phN/p01Gxa4CjzOxn\nhNac9wHFnZ978xXgNjP7A6FjdxfhNtiehKH/d5Zd+9VdSbjdd4eZ/ZiozxCwA7C2u3+jjHPNI7Re\nHWJmzxGmFfg3oRWoC7gn+vcDhM7YF/YzdpF+U58gkdqJcwvkRMKcNRcQRindRBj2Hff8cZKlZYRh\n4RfOxvQAAAFCSURBVEcR+v28B/iEu/8nX8DdryEkPEYY2n4doV/Hs6zed6Wc5OwwwjDprxESgq2B\nT7p7ccfq/iR8pX4H72xz96cJ8/q8Qrgl9jdCArgu4UMbd3+MMAx8PGEk08GE5GVRwbnmEW4hnkro\nHH4RoaP0/2/njm0aimIogF5qpsgMDJEZ6Jgi06RgA4qIIguAxAYehIbmpzBEkYCkCkLyOQN8PT/9\n4sp69vqrw1RV+ySb9Oj502fNx4m7S+euqtd0aLhN70V6Tr/XeU93mr7V91vdP6mqj/TY/C49HbhP\n38ldunt36Vun97okeUiySneY3tLvzF7S+4u26f/5Pr3n6PHc2eAv3CzLv92gDwBwNTpBAMBIQhAA\nMJIQBACMJAQBACMJQQDASEIQADCSEAQAjCQEAQAjCUEAwEhCEAAwkhAEAIx0AFLjAha3wWCdAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f68e6ac90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_auc_df['counts'],all_auc_df['netmhc_xgb']-all_auc_df['netmhc'],'o')\n",
    "plt.axhline(0,c='g')\n",
    "plt.xlabel('number of measurements')\n",
    "plt.ylabel(' netmc & xgb AUC - netmhc AUC')\n",
    "_=plt.xlim(100,1000)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
